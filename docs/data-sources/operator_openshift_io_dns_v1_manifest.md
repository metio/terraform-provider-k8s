---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "k8s_operator_openshift_io_dns_v1_manifest Data Source - terraform-provider-k8s"
subcategory: "operator.openshift.io"
description: |-
  DNS manages the CoreDNS component to provide a name resolution service for pods and services in the cluster.  This supports the DNS-based service discovery specification: https://github.com/kubernetes/dns/blob/master/docs/specification.md  More details: https://kubernetes.io/docs/tasks/administer-cluster/coredns  Compatibility level 1: Stable within a major release for a minimum of 12 months or 3 minor releases (whichever is longer).
---

# k8s_operator_openshift_io_dns_v1_manifest (Data Source)

DNS manages the CoreDNS component to provide a name resolution service for pods and services in the cluster.  This supports the DNS-based service discovery specification: https://github.com/kubernetes/dns/blob/master/docs/specification.md  More details: https://kubernetes.io/docs/tasks/administer-cluster/coredns  Compatibility level 1: Stable within a major release for a minimum of 12 months or 3 minor releases (whichever is longer).

## Example Usage

```terraform
data "k8s_operator_openshift_io_dns_v1_manifest" "example" {
  metadata = {
    name = "some-name"

  }
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `metadata` (Attributes) Data that helps uniquely identify this object. See https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#metadata for more details. (see [below for nested schema](#nestedatt--metadata))

### Optional

- `spec` (Attributes) spec is the specification of the desired behavior of the DNS. (see [below for nested schema](#nestedatt--spec))

### Read-Only

- `yaml` (String) The generated manifest in YAML format.

<a id="nestedatt--metadata"></a>
### Nested Schema for `metadata`

Required:

- `name` (String) Unique identifier for this object. See https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names for more details.

Optional:

- `annotations` (Map of String) Keys and values that can be used by external tooling to store and retrieve arbitrary metadata about this object. See https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/ for more details.
- `labels` (Map of String) Keys and values that can be used to organize and categorize objects. See https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/ for more details.


<a id="nestedatt--spec"></a>
### Nested Schema for `spec`

Optional:

- `cache` (Attributes) cache describes the caching configuration that applies to all server blocks listed in the Corefile. This field allows a cluster admin to optionally configure: * positiveTTL which is a duration for which positive responses should be cached. * negativeTTL which is a duration for which negative responses should be cached. If this is not configured, OpenShift will configure positive and negative caching with a default value that is subject to change. At the time of writing, the default positiveTTL is 900 seconds and the default negativeTTL is 30 seconds or as noted in the respective Corefile for your version of OpenShift. (see [below for nested schema](#nestedatt--spec--cache))
- `log_level` (String) logLevel describes the desired logging verbosity for CoreDNS. Any one of the following values may be specified: * Normal logs errors from upstream resolvers. * Debug logs errors, NXDOMAIN responses, and NODATA responses. * Trace logs errors and all responses. Setting logLevel: Trace will produce extremely verbose logs. Valid values are: 'Normal', 'Debug', 'Trace'. Defaults to 'Normal'.
- `management_state` (String) managementState indicates whether the DNS operator should manage cluster DNS
- `node_placement` (Attributes) nodePlacement provides explicit control over the scheduling of DNS pods.  Generally, it is useful to run a DNS pod on every node so that DNS queries are always handled by a local DNS pod instead of going over the network to a DNS pod on another node.  However, security policies may require restricting the placement of DNS pods to specific nodes. For example, if a security policy prohibits pods on arbitrary nodes from communicating with the API, a node selector can be specified to restrict DNS pods to nodes that are permitted to communicate with the API.  Conversely, if running DNS pods on nodes with a particular taint is desired, a toleration can be specified for that taint.  If unset, defaults are used. See nodePlacement for more details. (see [below for nested schema](#nestedatt--spec--node_placement))
- `operator_log_level` (String) operatorLogLevel controls the logging level of the DNS Operator. Valid values are: 'Normal', 'Debug', 'Trace'. Defaults to 'Normal'. setting operatorLogLevel: Trace will produce extremely verbose logs.
- `servers` (Attributes List) servers is a list of DNS resolvers that provide name query delegation for one or more subdomains outside the scope of the cluster domain. If servers consists of more than one Server, longest suffix match will be used to determine the Server.  For example, if there are two Servers, one for 'foo.com' and another for 'a.foo.com', and the name query is for 'www.a.foo.com', it will be routed to the Server with Zone 'a.foo.com'.  If this field is nil, no servers are created. (see [below for nested schema](#nestedatt--spec--servers))
- `upstream_resolvers` (Attributes) upstreamResolvers defines a schema for configuring CoreDNS to proxy DNS messages to upstream resolvers for the case of the default ('.') server  If this field is not specified, the upstream used will default to /etc/resolv.conf, with policy 'sequential' (see [below for nested schema](#nestedatt--spec--upstream_resolvers))

<a id="nestedatt--spec--cache"></a>
### Nested Schema for `spec.cache`

Optional:

- `negative_ttl` (String) negativeTTL is optional and specifies the amount of time that a negative response should be cached.  If configured, it must be a value of 1s (1 second) or greater up to a theoretical maximum of several years. This field expects an unsigned duration string of decimal numbers, each with optional fraction and a unit suffix, e.g. '100s', '1m30s', '12h30m10s'. Values that are fractions of a second are rounded down to the nearest second. If the configured value is less than 1s, the default value will be used. If not configured, the value will be 0s and OpenShift will use a default value of 30 seconds unless noted otherwise in the respective Corefile for your version of OpenShift. The default value of 30 seconds is subject to change.
- `positive_ttl` (String) positiveTTL is optional and specifies the amount of time that a positive response should be cached.  If configured, it must be a value of 1s (1 second) or greater up to a theoretical maximum of several years. This field expects an unsigned duration string of decimal numbers, each with optional fraction and a unit suffix, e.g. '100s', '1m30s', '12h30m10s'. Values that are fractions of a second are rounded down to the nearest second. If the configured value is less than 1s, the default value will be used. If not configured, the value will be 0s and OpenShift will use a default value of 900 seconds unless noted otherwise in the respective Corefile for your version of OpenShift. The default value of 900 seconds is subject to change.


<a id="nestedatt--spec--node_placement"></a>
### Nested Schema for `spec.node_placement`

Optional:

- `node_selector` (Map of String) nodeSelector is the node selector applied to DNS pods.  If empty, the default is used, which is currently the following:  kubernetes.io/os: linux  This default is subject to change.  If set, the specified selector is used and replaces the default.
- `tolerations` (Attributes List) tolerations is a list of tolerations applied to DNS pods.  If empty, the DNS operator sets a toleration for the 'node-role.kubernetes.io/master' taint.  This default is subject to change.  Specifying tolerations without including a toleration for the 'node-role.kubernetes.io/master' taint may be risky as it could lead to an outage if all worker nodes become unavailable.  Note that the daemon controller adds some tolerations as well.  See https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/ (see [below for nested schema](#nestedatt--spec--node_placement--tolerations))

<a id="nestedatt--spec--node_placement--tolerations"></a>
### Nested Schema for `spec.node_placement.tolerations`

Optional:

- `effect` (String) Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
- `key` (String) Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
- `operator` (String) Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
- `toleration_seconds` (Number) TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
- `value` (String) Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.



<a id="nestedatt--spec--servers"></a>
### Nested Schema for `spec.servers`

Optional:

- `forward_plugin` (Attributes) forwardPlugin defines a schema for configuring CoreDNS to proxy DNS messages to upstream resolvers. (see [below for nested schema](#nestedatt--spec--servers--forward_plugin))
- `name` (String) name is required and specifies a unique name for the server. Name must comply with the Service Name Syntax of rfc6335.
- `zones` (List of String) zones is required and specifies the subdomains that Server is authoritative for. Zones must conform to the rfc1123 definition of a subdomain. Specifying the cluster domain (i.e., 'cluster.local') is invalid.

<a id="nestedatt--spec--servers--forward_plugin"></a>
### Nested Schema for `spec.servers.forward_plugin`

Optional:

- `policy` (String) policy is used to determine the order in which upstream servers are selected for querying. Any one of the following values may be specified:  * 'Random' picks a random upstream server for each query. * 'RoundRobin' picks upstream servers in a round-robin order, moving to the next server for each new query. * 'Sequential' tries querying upstream servers in a sequential order until one responds, starting with the first server for each new query.  The default value is 'Random'
- `protocol_strategy` (String) protocolStrategy specifies the protocol to use for upstream DNS requests. Valid values for protocolStrategy are 'TCP' and omitted. When omitted, this means no opinion and the platform is left to choose a reasonable default, which is subject to change over time. The current default is to use the protocol of the original client request. 'TCP' specifies that the platform should use TCP for all upstream DNS requests, even if the client request uses UDP. 'TCP' is useful for UDP-specific issues such as those created by non-compliant upstream resolvers, but may consume more bandwidth or increase DNS response time. Note that protocolStrategy only affects the protocol of DNS requests that CoreDNS makes to upstream resolvers. It does not affect the protocol of DNS requests between clients and CoreDNS.
- `transport_config` (Attributes) transportConfig is used to configure the transport type, server name, and optional custom CA or CA bundle to use when forwarding DNS requests to an upstream resolver.  The default value is '' (empty) which results in a standard cleartext connection being used when forwarding DNS requests to an upstream resolver. (see [below for nested schema](#nestedatt--spec--servers--forward_plugin--transport_config))
- `upstreams` (List of String) upstreams is a list of resolvers to forward name queries for subdomains of Zones. Each instance of CoreDNS performs health checking of Upstreams. When a healthy upstream returns an error during the exchange, another resolver is tried from Upstreams. The Upstreams are selected in the order specified in Policy. Each upstream is represented by an IP address or IP:port if the upstream listens on a port other than 53.  A maximum of 15 upstreams is allowed per ForwardPlugin.

<a id="nestedatt--spec--servers--forward_plugin--transport_config"></a>
### Nested Schema for `spec.servers.forward_plugin.upstreams`

Optional:

- `tls` (Attributes) tls contains the additional configuration options to use when Transport is set to 'TLS'. (see [below for nested schema](#nestedatt--spec--servers--forward_plugin--upstreams--tls))
- `transport` (String) transport allows cluster administrators to opt-in to using a DNS-over-TLS connection between cluster DNS and an upstream resolver(s). Configuring TLS as the transport at this level without configuring a CABundle will result in the system certificates being used to verify the serving certificate of the upstream resolver(s).  Possible values: '' (empty) - This means no explicit choice has been made and the platform chooses the default which is subject to change over time. The current default is 'Cleartext'. 'Cleartext' - Cluster admin specified cleartext option. This results in the same functionality as an empty value but may be useful when a cluster admin wants to be more explicit about the transport, or wants to switch from 'TLS' to 'Cleartext' explicitly. 'TLS' - This indicates that DNS queries should be sent over a TLS connection. If Transport is set to TLS, you MUST also set ServerName. If a port is not included with the upstream IP, port 853 will be tried by default per RFC 7858 section 3.1; https://datatracker.ietf.org/doc/html/rfc7858#section-3.1.

<a id="nestedatt--spec--servers--forward_plugin--upstreams--tls"></a>
### Nested Schema for `spec.servers.forward_plugin.upstreams.tls`

Required:

- `server_name` (String) serverName is the upstream server to connect to when forwarding DNS queries. This is required when Transport is set to 'TLS'. ServerName will be validated against the DNS naming conventions in RFC 1123 and should match the TLS certificate installed in the upstream resolver(s).

Optional:

- `ca_bundle` (Attributes) caBundle references a ConfigMap that must contain either a single CA Certificate or a CA Bundle. This allows cluster administrators to provide their own CA or CA bundle for validating the certificate of upstream resolvers.  1. The configmap must contain a 'ca-bundle.crt' key. 2. The value must be a PEM encoded CA certificate or CA bundle. 3. The administrator must create this configmap in the openshift-config namespace. 4. The upstream server certificate must contain a Subject Alternative Name (SAN) that matches ServerName. (see [below for nested schema](#nestedatt--spec--servers--forward_plugin--upstreams--tls--ca_bundle))

<a id="nestedatt--spec--servers--forward_plugin--upstreams--tls--ca_bundle"></a>
### Nested Schema for `spec.servers.forward_plugin.upstreams.tls.ca_bundle`

Required:

- `name` (String) name is the metadata.name of the referenced config map






<a id="nestedatt--spec--upstream_resolvers"></a>
### Nested Schema for `spec.upstream_resolvers`

Optional:

- `policy` (String) Policy is used to determine the order in which upstream servers are selected for querying. Any one of the following values may be specified:  * 'Random' picks a random upstream server for each query. * 'RoundRobin' picks upstream servers in a round-robin order, moving to the next server for each new query. * 'Sequential' tries querying upstream servers in a sequential order until one responds, starting with the first server for each new query.  The default value is 'Sequential'
- `protocol_strategy` (String) protocolStrategy specifies the protocol to use for upstream DNS requests. Valid values for protocolStrategy are 'TCP' and omitted. When omitted, this means no opinion and the platform is left to choose a reasonable default, which is subject to change over time. The current default is to use the protocol of the original client request. 'TCP' specifies that the platform should use TCP for all upstream DNS requests, even if the client request uses UDP. 'TCP' is useful for UDP-specific issues such as those created by non-compliant upstream resolvers, but may consume more bandwidth or increase DNS response time. Note that protocolStrategy only affects the protocol of DNS requests that CoreDNS makes to upstream resolvers. It does not affect the protocol of DNS requests between clients and CoreDNS.
- `transport_config` (Attributes) transportConfig is used to configure the transport type, server name, and optional custom CA or CA bundle to use when forwarding DNS requests to an upstream resolver.  The default value is '' (empty) which results in a standard cleartext connection being used when forwarding DNS requests to an upstream resolver. (see [below for nested schema](#nestedatt--spec--upstream_resolvers--transport_config))
- `upstreams` (Attributes List) Upstreams is a list of resolvers to forward name queries for the '.' domain. Each instance of CoreDNS performs health checking of Upstreams. When a healthy upstream returns an error during the exchange, another resolver is tried from Upstreams. The Upstreams are selected in the order specified in Policy.  A maximum of 15 upstreams is allowed per ForwardPlugin. If no Upstreams are specified, /etc/resolv.conf is used by default (see [below for nested schema](#nestedatt--spec--upstream_resolvers--upstreams))

<a id="nestedatt--spec--upstream_resolvers--transport_config"></a>
### Nested Schema for `spec.upstream_resolvers.transport_config`

Optional:

- `tls` (Attributes) tls contains the additional configuration options to use when Transport is set to 'TLS'. (see [below for nested schema](#nestedatt--spec--upstream_resolvers--transport_config--tls))
- `transport` (String) transport allows cluster administrators to opt-in to using a DNS-over-TLS connection between cluster DNS and an upstream resolver(s). Configuring TLS as the transport at this level without configuring a CABundle will result in the system certificates being used to verify the serving certificate of the upstream resolver(s).  Possible values: '' (empty) - This means no explicit choice has been made and the platform chooses the default which is subject to change over time. The current default is 'Cleartext'. 'Cleartext' - Cluster admin specified cleartext option. This results in the same functionality as an empty value but may be useful when a cluster admin wants to be more explicit about the transport, or wants to switch from 'TLS' to 'Cleartext' explicitly. 'TLS' - This indicates that DNS queries should be sent over a TLS connection. If Transport is set to TLS, you MUST also set ServerName. If a port is not included with the upstream IP, port 853 will be tried by default per RFC 7858 section 3.1; https://datatracker.ietf.org/doc/html/rfc7858#section-3.1.

<a id="nestedatt--spec--upstream_resolvers--transport_config--tls"></a>
### Nested Schema for `spec.upstream_resolvers.transport_config.transport`

Required:

- `server_name` (String) serverName is the upstream server to connect to when forwarding DNS queries. This is required when Transport is set to 'TLS'. ServerName will be validated against the DNS naming conventions in RFC 1123 and should match the TLS certificate installed in the upstream resolver(s).

Optional:

- `ca_bundle` (Attributes) caBundle references a ConfigMap that must contain either a single CA Certificate or a CA Bundle. This allows cluster administrators to provide their own CA or CA bundle for validating the certificate of upstream resolvers.  1. The configmap must contain a 'ca-bundle.crt' key. 2. The value must be a PEM encoded CA certificate or CA bundle. 3. The administrator must create this configmap in the openshift-config namespace. 4. The upstream server certificate must contain a Subject Alternative Name (SAN) that matches ServerName. (see [below for nested schema](#nestedatt--spec--upstream_resolvers--transport_config--transport--ca_bundle))

<a id="nestedatt--spec--upstream_resolvers--transport_config--transport--ca_bundle"></a>
### Nested Schema for `spec.upstream_resolvers.transport_config.transport.ca_bundle`

Required:

- `name` (String) name is the metadata.name of the referenced config map




<a id="nestedatt--spec--upstream_resolvers--upstreams"></a>
### Nested Schema for `spec.upstream_resolvers.upstreams`

Required:

- `type` (String) Type defines whether this upstream contains an IP/IP:port resolver or the local /etc/resolv.conf. Type accepts 2 possible values: SystemResolvConf or Network.  * When SystemResolvConf is used, the Upstream structure does not require any further fields to be defined: /etc/resolv.conf will be used * When Network is used, the Upstream structure must contain at least an Address

Optional:

- `address` (String) Address must be defined when Type is set to Network. It will be ignored otherwise. It must be a valid ipv4 or ipv6 address.
- `port` (Number) Port may be defined when Type is set to Network. It will be ignored otherwise. Port must be between 65535
