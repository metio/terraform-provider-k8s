---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "k8s_slo_koordinator_sh_node_slo_v1alpha1 Resource - terraform-provider-k8s"
subcategory: "slo.koordinator.sh"
description: |-
  NodeSLO is the Schema for the nodeslos API
---

# k8s_slo_koordinator_sh_node_slo_v1alpha1 (Resource)

NodeSLO is the Schema for the nodeslos API

## Example Usage

```terraform
resource "k8s_slo_koordinator_sh_node_slo_v1alpha1" "minimal" {
  metadata = {
    name = "test"
  }
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `metadata` (Attributes) Data that helps uniquely identify this object. See https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#metadata for more details. (see [below for nested schema](#nestedatt--metadata))

### Optional

- `spec` (Attributes) NodeSLOSpec defines the desired state of NodeSLO (see [below for nested schema](#nestedatt--spec))

### Read-Only

- `api_version` (String) APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
- `id` (Number) The timestamp of the last change to this resource.
- `kind` (String) Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
- `yaml` (String) The generated manifest in YAML format.

<a id="nestedatt--metadata"></a>
### Nested Schema for `metadata`

Required:

- `name` (String) Unique identifier for this object. See https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names for more details.

Optional:

- `annotations` (Map of String) Keys and values that can be used by external tooling to store and retrieve arbitrary metadata about this object. See https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/ for more details.
- `labels` (Map of String) Keys and values that can be used to organize and categorize objects. See https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/ for more details.


<a id="nestedatt--spec"></a>
### Nested Schema for `spec`

Optional:

- `cpu_burst_strategy` (Attributes) CPU Burst Strategy (see [below for nested schema](#nestedatt--spec--cpu_burst_strategy))
- `extensions` (Dynamic) Third party extensions for NodeSLO
- `resource_qos_strategy` (Attributes) QoS config strategy for pods of different qos-class (see [below for nested schema](#nestedatt--spec--resource_qos_strategy))
- `resource_used_threshold_with_be` (Attributes) BE pods will be limited if node resource usage overload (see [below for nested schema](#nestedatt--spec--resource_used_threshold_with_be))

<a id="nestedatt--spec--cpu_burst_strategy"></a>
### Nested Schema for `spec.cpu_burst_strategy`

Optional:

- `cfs_quota_burst_percent` (Number) pod cfs quota scale up ceil percentage, default = 300 (300%)
- `cfs_quota_burst_period_seconds` (Number) specifies a period of time for pod can use at burst, default = -1 (unlimited)
- `cpu_burst_percent` (Number) cpu burst percentage for setting cpu.cfs_burst_us, legal range: [0, 10000], default as 1000 (1000%)
- `policy` (String)
- `share_pool_threshold_percent` (Number) scale down cfs quota if node cpu overload, default = 50


<a id="nestedatt--spec--resource_qos_strategy"></a>
### Nested Schema for `spec.resource_qos_strategy`

Optional:

- `be_class` (Attributes) ResourceQOS for BE pods. (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--be_class))
- `cgroup_root` (Attributes) ResourceQOS for root cgroup. (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--cgroup_root))
- `ls_class` (Attributes) ResourceQOS for LS pods. (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--ls_class))
- `lsr_class` (Attributes) ResourceQOS for LSR pods. (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--lsr_class))
- `system_class` (Attributes) ResourceQOS for system pods (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--system_class))

<a id="nestedatt--spec--resource_qos_strategy--be_class"></a>
### Nested Schema for `spec.resource_qos_strategy.be_class`

Optional:

- `cpu_qos` (Attributes) CPUQOSCfg stores node-level config of cpu qos (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--be_class--cpu_qos))
- `memory_qos` (Attributes) MemoryQOSCfg stores node-level config of memory qos (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--be_class--memory_qos))
- `resctrl_qos` (Attributes) ResctrlQOSCfg stores node-level config of resctrl qos (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--be_class--resctrl_qos))

<a id="nestedatt--spec--resource_qos_strategy--be_class--cpu_qos"></a>
### Nested Schema for `spec.resource_qos_strategy.be_class.resctrl_qos`

Optional:

- `enable` (Boolean) Enable indicates whether the cpu qos is enabled.
- `group_identity` (Number) group identity value for pods, default = 0


<a id="nestedatt--spec--resource_qos_strategy--be_class--memory_qos"></a>
### Nested Schema for `spec.resource_qos_strategy.be_class.resctrl_qos`

Optional:

- `enable` (Boolean) Enable indicates whether the memory qos is enabled (default: false). This field is used for node-level control, while pod-level configuration is done with MemoryQOS and 'Policy' instead of an 'Enable' option. Please view the differences between MemoryQOSCfg and PodMemoryQOSConfig structs.
- `low_limit_percent` (Number) LowLimitPercent specifies the lowLimitFactor percentage to calculate 'memory.low', which TRIES BEST protecting memory from global reclamation when memory usage does not exceed the low limit unless no unprotected memcg can be reclaimed. NOTE: 'memory.low' should be larger than 'memory.min'. If spec.requests.memory == spec.limits.memory, pod 'memory.low' and 'memory.high' become invalid, while 'memory.wmark_ratio' is still in effect. Close: 0.
- `min_limit_percent` (Number) memcg qos If enabled, memcg qos will be set by the agent, where some fields are implicitly calculated from pod spec. 1. 'memory.min' := spec.requests.memory * minLimitFactor / 100 (use 0 if requests.memory is not set) 2. 'memory.low' := spec.requests.memory * lowLimitFactor / 100 (use 0 if requests.memory is not set) 3. 'memory.limit_in_bytes' := spec.limits.memory (set $node.allocatable.memory if limits.memory is not set) 4. 'memory.high' := memory.limit_in_bytes * throttlingFactor / 100 (use 'max' if memory.high <= memory.min) MinLimitPercent specifies the minLimitFactor percentage to calculate 'memory.min', which protects memory from global reclamation when memory usage does not exceed the min limit. Close: 0.
- `oom_kill_group` (Number)
- `priority` (Number)
- `priority_enable` (Number) TODO: enhance the usages of oom priority and oom kill group
- `throttling_percent` (Number) ThrottlingPercent specifies the throttlingFactor percentage to calculate 'memory.high' with pod memory.limits or node allocatable memory, which triggers memcg direct reclamation when memory usage exceeds. Lower the factor brings more heavier reclaim pressure. Close: 0.
- `wmark_min_adj` (Number) wmark_min_adj (Anolis OS required) WmarkMinAdj specifies 'memory.wmark_min_adj' which adjusts per-memcg threshold for global memory reclamation. Lower the factor brings later reclamation. The adjustment uses different formula for different value range. [-25, 0)：global_wmark_min' = global_wmark_min + (global_wmark_min - 0) * wmarkMinAdj (0, 50]：global_wmark_min' = global_wmark_min + (global_wmark_low - global_wmark_min) * wmarkMinAdj Close: [LSR:0, LS:0, BE:0]. Recommended: [LSR:-25, LS:-25, BE:50].
- `wmark_ratio` (Number) wmark_ratio (Anolis OS required) Async memory reclamation is triggered when cgroup memory usage exceeds 'memory.wmark_high' and the reclamation stops when usage is below 'memory.wmark_low'. Basically, 'memory.wmark_high' := min(memory.high, memory.limit_in_bytes) * memory.memory.wmark_ratio 'memory.wmark_low' := min(memory.high, memory.limit_in_bytes) * (memory.wmark_ratio - memory.wmark_scale_factor) WmarkRatio specifies 'memory.wmark_ratio' that help calculate 'memory.wmark_high', which triggers async memory reclamation when memory usage exceeds. Close: 0. Recommended: 95.
- `wmark_scale_permill` (Number) WmarkScalePermill specifies 'memory.wmark_scale_factor' that helps calculate 'memory.wmark_low', which stops async memory reclamation when memory usage belows. Close: 50. Recommended: 20.


<a id="nestedatt--spec--resource_qos_strategy--be_class--resctrl_qos"></a>
### Nested Schema for `spec.resource_qos_strategy.be_class.resctrl_qos`

Optional:

- `cat_range_end_percent` (Number) LLC available range end for pods by percentage
- `cat_range_start_percent` (Number) LLC available range start for pods by percentage
- `enable` (Boolean) Enable indicates whether the resctrl qos is enabled.
- `mba_percent` (Number) MBA percent



<a id="nestedatt--spec--resource_qos_strategy--cgroup_root"></a>
### Nested Schema for `spec.resource_qos_strategy.cgroup_root`

Optional:

- `cpu_qos` (Attributes) CPUQOSCfg stores node-level config of cpu qos (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--cgroup_root--cpu_qos))
- `memory_qos` (Attributes) MemoryQOSCfg stores node-level config of memory qos (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--cgroup_root--memory_qos))
- `resctrl_qos` (Attributes) ResctrlQOSCfg stores node-level config of resctrl qos (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--cgroup_root--resctrl_qos))

<a id="nestedatt--spec--resource_qos_strategy--cgroup_root--cpu_qos"></a>
### Nested Schema for `spec.resource_qos_strategy.cgroup_root.resctrl_qos`

Optional:

- `enable` (Boolean) Enable indicates whether the cpu qos is enabled.
- `group_identity` (Number) group identity value for pods, default = 0


<a id="nestedatt--spec--resource_qos_strategy--cgroup_root--memory_qos"></a>
### Nested Schema for `spec.resource_qos_strategy.cgroup_root.resctrl_qos`

Optional:

- `enable` (Boolean) Enable indicates whether the memory qos is enabled (default: false). This field is used for node-level control, while pod-level configuration is done with MemoryQOS and 'Policy' instead of an 'Enable' option. Please view the differences between MemoryQOSCfg and PodMemoryQOSConfig structs.
- `low_limit_percent` (Number) LowLimitPercent specifies the lowLimitFactor percentage to calculate 'memory.low', which TRIES BEST protecting memory from global reclamation when memory usage does not exceed the low limit unless no unprotected memcg can be reclaimed. NOTE: 'memory.low' should be larger than 'memory.min'. If spec.requests.memory == spec.limits.memory, pod 'memory.low' and 'memory.high' become invalid, while 'memory.wmark_ratio' is still in effect. Close: 0.
- `min_limit_percent` (Number) memcg qos If enabled, memcg qos will be set by the agent, where some fields are implicitly calculated from pod spec. 1. 'memory.min' := spec.requests.memory * minLimitFactor / 100 (use 0 if requests.memory is not set) 2. 'memory.low' := spec.requests.memory * lowLimitFactor / 100 (use 0 if requests.memory is not set) 3. 'memory.limit_in_bytes' := spec.limits.memory (set $node.allocatable.memory if limits.memory is not set) 4. 'memory.high' := memory.limit_in_bytes * throttlingFactor / 100 (use 'max' if memory.high <= memory.min) MinLimitPercent specifies the minLimitFactor percentage to calculate 'memory.min', which protects memory from global reclamation when memory usage does not exceed the min limit. Close: 0.
- `oom_kill_group` (Number)
- `priority` (Number)
- `priority_enable` (Number) TODO: enhance the usages of oom priority and oom kill group
- `throttling_percent` (Number) ThrottlingPercent specifies the throttlingFactor percentage to calculate 'memory.high' with pod memory.limits or node allocatable memory, which triggers memcg direct reclamation when memory usage exceeds. Lower the factor brings more heavier reclaim pressure. Close: 0.
- `wmark_min_adj` (Number) wmark_min_adj (Anolis OS required) WmarkMinAdj specifies 'memory.wmark_min_adj' which adjusts per-memcg threshold for global memory reclamation. Lower the factor brings later reclamation. The adjustment uses different formula for different value range. [-25, 0)：global_wmark_min' = global_wmark_min + (global_wmark_min - 0) * wmarkMinAdj (0, 50]：global_wmark_min' = global_wmark_min + (global_wmark_low - global_wmark_min) * wmarkMinAdj Close: [LSR:0, LS:0, BE:0]. Recommended: [LSR:-25, LS:-25, BE:50].
- `wmark_ratio` (Number) wmark_ratio (Anolis OS required) Async memory reclamation is triggered when cgroup memory usage exceeds 'memory.wmark_high' and the reclamation stops when usage is below 'memory.wmark_low'. Basically, 'memory.wmark_high' := min(memory.high, memory.limit_in_bytes) * memory.memory.wmark_ratio 'memory.wmark_low' := min(memory.high, memory.limit_in_bytes) * (memory.wmark_ratio - memory.wmark_scale_factor) WmarkRatio specifies 'memory.wmark_ratio' that help calculate 'memory.wmark_high', which triggers async memory reclamation when memory usage exceeds. Close: 0. Recommended: 95.
- `wmark_scale_permill` (Number) WmarkScalePermill specifies 'memory.wmark_scale_factor' that helps calculate 'memory.wmark_low', which stops async memory reclamation when memory usage belows. Close: 50. Recommended: 20.


<a id="nestedatt--spec--resource_qos_strategy--cgroup_root--resctrl_qos"></a>
### Nested Schema for `spec.resource_qos_strategy.cgroup_root.resctrl_qos`

Optional:

- `cat_range_end_percent` (Number) LLC available range end for pods by percentage
- `cat_range_start_percent` (Number) LLC available range start for pods by percentage
- `enable` (Boolean) Enable indicates whether the resctrl qos is enabled.
- `mba_percent` (Number) MBA percent



<a id="nestedatt--spec--resource_qos_strategy--ls_class"></a>
### Nested Schema for `spec.resource_qos_strategy.ls_class`

Optional:

- `cpu_qos` (Attributes) CPUQOSCfg stores node-level config of cpu qos (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--ls_class--cpu_qos))
- `memory_qos` (Attributes) MemoryQOSCfg stores node-level config of memory qos (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--ls_class--memory_qos))
- `resctrl_qos` (Attributes) ResctrlQOSCfg stores node-level config of resctrl qos (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--ls_class--resctrl_qos))

<a id="nestedatt--spec--resource_qos_strategy--ls_class--cpu_qos"></a>
### Nested Schema for `spec.resource_qos_strategy.ls_class.resctrl_qos`

Optional:

- `enable` (Boolean) Enable indicates whether the cpu qos is enabled.
- `group_identity` (Number) group identity value for pods, default = 0


<a id="nestedatt--spec--resource_qos_strategy--ls_class--memory_qos"></a>
### Nested Schema for `spec.resource_qos_strategy.ls_class.resctrl_qos`

Optional:

- `enable` (Boolean) Enable indicates whether the memory qos is enabled (default: false). This field is used for node-level control, while pod-level configuration is done with MemoryQOS and 'Policy' instead of an 'Enable' option. Please view the differences between MemoryQOSCfg and PodMemoryQOSConfig structs.
- `low_limit_percent` (Number) LowLimitPercent specifies the lowLimitFactor percentage to calculate 'memory.low', which TRIES BEST protecting memory from global reclamation when memory usage does not exceed the low limit unless no unprotected memcg can be reclaimed. NOTE: 'memory.low' should be larger than 'memory.min'. If spec.requests.memory == spec.limits.memory, pod 'memory.low' and 'memory.high' become invalid, while 'memory.wmark_ratio' is still in effect. Close: 0.
- `min_limit_percent` (Number) memcg qos If enabled, memcg qos will be set by the agent, where some fields are implicitly calculated from pod spec. 1. 'memory.min' := spec.requests.memory * minLimitFactor / 100 (use 0 if requests.memory is not set) 2. 'memory.low' := spec.requests.memory * lowLimitFactor / 100 (use 0 if requests.memory is not set) 3. 'memory.limit_in_bytes' := spec.limits.memory (set $node.allocatable.memory if limits.memory is not set) 4. 'memory.high' := memory.limit_in_bytes * throttlingFactor / 100 (use 'max' if memory.high <= memory.min) MinLimitPercent specifies the minLimitFactor percentage to calculate 'memory.min', which protects memory from global reclamation when memory usage does not exceed the min limit. Close: 0.
- `oom_kill_group` (Number)
- `priority` (Number)
- `priority_enable` (Number) TODO: enhance the usages of oom priority and oom kill group
- `throttling_percent` (Number) ThrottlingPercent specifies the throttlingFactor percentage to calculate 'memory.high' with pod memory.limits or node allocatable memory, which triggers memcg direct reclamation when memory usage exceeds. Lower the factor brings more heavier reclaim pressure. Close: 0.
- `wmark_min_adj` (Number) wmark_min_adj (Anolis OS required) WmarkMinAdj specifies 'memory.wmark_min_adj' which adjusts per-memcg threshold for global memory reclamation. Lower the factor brings later reclamation. The adjustment uses different formula for different value range. [-25, 0)：global_wmark_min' = global_wmark_min + (global_wmark_min - 0) * wmarkMinAdj (0, 50]：global_wmark_min' = global_wmark_min + (global_wmark_low - global_wmark_min) * wmarkMinAdj Close: [LSR:0, LS:0, BE:0]. Recommended: [LSR:-25, LS:-25, BE:50].
- `wmark_ratio` (Number) wmark_ratio (Anolis OS required) Async memory reclamation is triggered when cgroup memory usage exceeds 'memory.wmark_high' and the reclamation stops when usage is below 'memory.wmark_low'. Basically, 'memory.wmark_high' := min(memory.high, memory.limit_in_bytes) * memory.memory.wmark_ratio 'memory.wmark_low' := min(memory.high, memory.limit_in_bytes) * (memory.wmark_ratio - memory.wmark_scale_factor) WmarkRatio specifies 'memory.wmark_ratio' that help calculate 'memory.wmark_high', which triggers async memory reclamation when memory usage exceeds. Close: 0. Recommended: 95.
- `wmark_scale_permill` (Number) WmarkScalePermill specifies 'memory.wmark_scale_factor' that helps calculate 'memory.wmark_low', which stops async memory reclamation when memory usage belows. Close: 50. Recommended: 20.


<a id="nestedatt--spec--resource_qos_strategy--ls_class--resctrl_qos"></a>
### Nested Schema for `spec.resource_qos_strategy.ls_class.resctrl_qos`

Optional:

- `cat_range_end_percent` (Number) LLC available range end for pods by percentage
- `cat_range_start_percent` (Number) LLC available range start for pods by percentage
- `enable` (Boolean) Enable indicates whether the resctrl qos is enabled.
- `mba_percent` (Number) MBA percent



<a id="nestedatt--spec--resource_qos_strategy--lsr_class"></a>
### Nested Schema for `spec.resource_qos_strategy.lsr_class`

Optional:

- `cpu_qos` (Attributes) CPUQOSCfg stores node-level config of cpu qos (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--lsr_class--cpu_qos))
- `memory_qos` (Attributes) MemoryQOSCfg stores node-level config of memory qos (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--lsr_class--memory_qos))
- `resctrl_qos` (Attributes) ResctrlQOSCfg stores node-level config of resctrl qos (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--lsr_class--resctrl_qos))

<a id="nestedatt--spec--resource_qos_strategy--lsr_class--cpu_qos"></a>
### Nested Schema for `spec.resource_qos_strategy.lsr_class.resctrl_qos`

Optional:

- `enable` (Boolean) Enable indicates whether the cpu qos is enabled.
- `group_identity` (Number) group identity value for pods, default = 0


<a id="nestedatt--spec--resource_qos_strategy--lsr_class--memory_qos"></a>
### Nested Schema for `spec.resource_qos_strategy.lsr_class.resctrl_qos`

Optional:

- `enable` (Boolean) Enable indicates whether the memory qos is enabled (default: false). This field is used for node-level control, while pod-level configuration is done with MemoryQOS and 'Policy' instead of an 'Enable' option. Please view the differences between MemoryQOSCfg and PodMemoryQOSConfig structs.
- `low_limit_percent` (Number) LowLimitPercent specifies the lowLimitFactor percentage to calculate 'memory.low', which TRIES BEST protecting memory from global reclamation when memory usage does not exceed the low limit unless no unprotected memcg can be reclaimed. NOTE: 'memory.low' should be larger than 'memory.min'. If spec.requests.memory == spec.limits.memory, pod 'memory.low' and 'memory.high' become invalid, while 'memory.wmark_ratio' is still in effect. Close: 0.
- `min_limit_percent` (Number) memcg qos If enabled, memcg qos will be set by the agent, where some fields are implicitly calculated from pod spec. 1. 'memory.min' := spec.requests.memory * minLimitFactor / 100 (use 0 if requests.memory is not set) 2. 'memory.low' := spec.requests.memory * lowLimitFactor / 100 (use 0 if requests.memory is not set) 3. 'memory.limit_in_bytes' := spec.limits.memory (set $node.allocatable.memory if limits.memory is not set) 4. 'memory.high' := memory.limit_in_bytes * throttlingFactor / 100 (use 'max' if memory.high <= memory.min) MinLimitPercent specifies the minLimitFactor percentage to calculate 'memory.min', which protects memory from global reclamation when memory usage does not exceed the min limit. Close: 0.
- `oom_kill_group` (Number)
- `priority` (Number)
- `priority_enable` (Number) TODO: enhance the usages of oom priority and oom kill group
- `throttling_percent` (Number) ThrottlingPercent specifies the throttlingFactor percentage to calculate 'memory.high' with pod memory.limits or node allocatable memory, which triggers memcg direct reclamation when memory usage exceeds. Lower the factor brings more heavier reclaim pressure. Close: 0.
- `wmark_min_adj` (Number) wmark_min_adj (Anolis OS required) WmarkMinAdj specifies 'memory.wmark_min_adj' which adjusts per-memcg threshold for global memory reclamation. Lower the factor brings later reclamation. The adjustment uses different formula for different value range. [-25, 0)：global_wmark_min' = global_wmark_min + (global_wmark_min - 0) * wmarkMinAdj (0, 50]：global_wmark_min' = global_wmark_min + (global_wmark_low - global_wmark_min) * wmarkMinAdj Close: [LSR:0, LS:0, BE:0]. Recommended: [LSR:-25, LS:-25, BE:50].
- `wmark_ratio` (Number) wmark_ratio (Anolis OS required) Async memory reclamation is triggered when cgroup memory usage exceeds 'memory.wmark_high' and the reclamation stops when usage is below 'memory.wmark_low'. Basically, 'memory.wmark_high' := min(memory.high, memory.limit_in_bytes) * memory.memory.wmark_ratio 'memory.wmark_low' := min(memory.high, memory.limit_in_bytes) * (memory.wmark_ratio - memory.wmark_scale_factor) WmarkRatio specifies 'memory.wmark_ratio' that help calculate 'memory.wmark_high', which triggers async memory reclamation when memory usage exceeds. Close: 0. Recommended: 95.
- `wmark_scale_permill` (Number) WmarkScalePermill specifies 'memory.wmark_scale_factor' that helps calculate 'memory.wmark_low', which stops async memory reclamation when memory usage belows. Close: 50. Recommended: 20.


<a id="nestedatt--spec--resource_qos_strategy--lsr_class--resctrl_qos"></a>
### Nested Schema for `spec.resource_qos_strategy.lsr_class.resctrl_qos`

Optional:

- `cat_range_end_percent` (Number) LLC available range end for pods by percentage
- `cat_range_start_percent` (Number) LLC available range start for pods by percentage
- `enable` (Boolean) Enable indicates whether the resctrl qos is enabled.
- `mba_percent` (Number) MBA percent



<a id="nestedatt--spec--resource_qos_strategy--system_class"></a>
### Nested Schema for `spec.resource_qos_strategy.system_class`

Optional:

- `cpu_qos` (Attributes) CPUQOSCfg stores node-level config of cpu qos (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--system_class--cpu_qos))
- `memory_qos` (Attributes) MemoryQOSCfg stores node-level config of memory qos (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--system_class--memory_qos))
- `resctrl_qos` (Attributes) ResctrlQOSCfg stores node-level config of resctrl qos (see [below for nested schema](#nestedatt--spec--resource_qos_strategy--system_class--resctrl_qos))

<a id="nestedatt--spec--resource_qos_strategy--system_class--cpu_qos"></a>
### Nested Schema for `spec.resource_qos_strategy.system_class.resctrl_qos`

Optional:

- `enable` (Boolean) Enable indicates whether the cpu qos is enabled.
- `group_identity` (Number) group identity value for pods, default = 0


<a id="nestedatt--spec--resource_qos_strategy--system_class--memory_qos"></a>
### Nested Schema for `spec.resource_qos_strategy.system_class.resctrl_qos`

Optional:

- `enable` (Boolean) Enable indicates whether the memory qos is enabled (default: false). This field is used for node-level control, while pod-level configuration is done with MemoryQOS and 'Policy' instead of an 'Enable' option. Please view the differences between MemoryQOSCfg and PodMemoryQOSConfig structs.
- `low_limit_percent` (Number) LowLimitPercent specifies the lowLimitFactor percentage to calculate 'memory.low', which TRIES BEST protecting memory from global reclamation when memory usage does not exceed the low limit unless no unprotected memcg can be reclaimed. NOTE: 'memory.low' should be larger than 'memory.min'. If spec.requests.memory == spec.limits.memory, pod 'memory.low' and 'memory.high' become invalid, while 'memory.wmark_ratio' is still in effect. Close: 0.
- `min_limit_percent` (Number) memcg qos If enabled, memcg qos will be set by the agent, where some fields are implicitly calculated from pod spec. 1. 'memory.min' := spec.requests.memory * minLimitFactor / 100 (use 0 if requests.memory is not set) 2. 'memory.low' := spec.requests.memory * lowLimitFactor / 100 (use 0 if requests.memory is not set) 3. 'memory.limit_in_bytes' := spec.limits.memory (set $node.allocatable.memory if limits.memory is not set) 4. 'memory.high' := memory.limit_in_bytes * throttlingFactor / 100 (use 'max' if memory.high <= memory.min) MinLimitPercent specifies the minLimitFactor percentage to calculate 'memory.min', which protects memory from global reclamation when memory usage does not exceed the min limit. Close: 0.
- `oom_kill_group` (Number)
- `priority` (Number)
- `priority_enable` (Number) TODO: enhance the usages of oom priority and oom kill group
- `throttling_percent` (Number) ThrottlingPercent specifies the throttlingFactor percentage to calculate 'memory.high' with pod memory.limits or node allocatable memory, which triggers memcg direct reclamation when memory usage exceeds. Lower the factor brings more heavier reclaim pressure. Close: 0.
- `wmark_min_adj` (Number) wmark_min_adj (Anolis OS required) WmarkMinAdj specifies 'memory.wmark_min_adj' which adjusts per-memcg threshold for global memory reclamation. Lower the factor brings later reclamation. The adjustment uses different formula for different value range. [-25, 0)：global_wmark_min' = global_wmark_min + (global_wmark_min - 0) * wmarkMinAdj (0, 50]：global_wmark_min' = global_wmark_min + (global_wmark_low - global_wmark_min) * wmarkMinAdj Close: [LSR:0, LS:0, BE:0]. Recommended: [LSR:-25, LS:-25, BE:50].
- `wmark_ratio` (Number) wmark_ratio (Anolis OS required) Async memory reclamation is triggered when cgroup memory usage exceeds 'memory.wmark_high' and the reclamation stops when usage is below 'memory.wmark_low'. Basically, 'memory.wmark_high' := min(memory.high, memory.limit_in_bytes) * memory.memory.wmark_ratio 'memory.wmark_low' := min(memory.high, memory.limit_in_bytes) * (memory.wmark_ratio - memory.wmark_scale_factor) WmarkRatio specifies 'memory.wmark_ratio' that help calculate 'memory.wmark_high', which triggers async memory reclamation when memory usage exceeds. Close: 0. Recommended: 95.
- `wmark_scale_permill` (Number) WmarkScalePermill specifies 'memory.wmark_scale_factor' that helps calculate 'memory.wmark_low', which stops async memory reclamation when memory usage belows. Close: 50. Recommended: 20.


<a id="nestedatt--spec--resource_qos_strategy--system_class--resctrl_qos"></a>
### Nested Schema for `spec.resource_qos_strategy.system_class.resctrl_qos`

Optional:

- `cat_range_end_percent` (Number) LLC available range end for pods by percentage
- `cat_range_start_percent` (Number) LLC available range start for pods by percentage
- `enable` (Boolean) Enable indicates whether the resctrl qos is enabled.
- `mba_percent` (Number) MBA percent




<a id="nestedatt--spec--resource_used_threshold_with_be"></a>
### Nested Schema for `spec.resource_used_threshold_with_be`

Optional:

- `cpu_evict_be_satisfaction_lower_percent` (Number) if be CPU (RealLimit/allocatedLimit < CPUEvictBESatisfactionLowerPercent and usage nearly 100%) continue CPUEvictTimeWindowSeconds,then start evict
- `cpu_evict_be_satisfaction_upper_percent` (Number) if be CPU RealLimit/allocatedLimit > CPUEvictBESatisfactionUpperPercent, then stop evict BE pods
- `cpu_evict_time_window_seconds` (Number) cpu evict start after continue avg(cpuusage) > CPUEvictThresholdPercent in seconds
- `cpu_suppress_policy` (String) CPUSuppressPolicy
- `cpu_suppress_threshold_percent` (Number) cpu suppress threshold percentage (0,100), default = 65
- `enable` (Boolean) whether the strategy is enabled, default = false
- `memory_evict_lower_percent` (Number) lower: memory release util usage under MemoryEvictLowerPercent, default = MemoryEvictThresholdPercent - 2
- `memory_evict_threshold_percent` (Number) upper: memory evict threshold percentage (0,100), default = 70


